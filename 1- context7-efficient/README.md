# üìö fetch-library-docs: 86.8% Token Reduction for Library Documentation

**Get instant code examples with 86.8% fewer tokens using intelligent Context7 filtering.**

[![Version](https://img.shields.io/badge/Version-1.0.0-blue)](CHANGELOG.md)
[![MCP Protocol](https://img.shields.io/badge/MCP-Context7-blue)](https://modelcontextprotocol.io/)
[![Token Savings](https://img.shields.io/badge/Token%20Savings-86.8%25-success)](.)
[![Architecture](https://img.shields.io/badge/Architecture-Shell%20Pipeline-orange)](https://www.anthropic.com/engineering/code-execution-with-mcp)

> **Note**: This skill was previously named `context7-efficient`. It has been renamed to `fetch-library-docs` for better AI agent discoverability following [tool naming best practices](https://tetrate.io/learn/ai/llm-function-calling-guide).

---

## üîë API Key Setup (Required)

Context7 now requires an API key for reliable access. Without an API key, you'll experience low rate limits or blocked requests.

### Get Your Free API Key

1. Visit **[context7.com/dashboard](https://context7.com/dashboard)**
2. Sign up or log in
3. Copy your API key (starts with `ctx7sk_`)

### Setup Methods (Choose One)

#### Method 1: Environment Variable (Advanced Users / CI/CD)

Best for automation, CI/CD pipelines, or temporary use.

**Windows (PowerShell):**
```powershell
# Temporary (current session only)
$env:CONTEXT7_API_KEY = "ctx7sk_your_api_key_here"

# Permanent (persists across sessions)
[Environment]::SetEnvironmentVariable("CONTEXT7_API_KEY", "ctx7sk_your_api_key_here", "User")
```

**Windows (Command Prompt):**
```cmd
# Permanent
setx CONTEXT7_API_KEY "ctx7sk_your_api_key_here"
```

**macOS/Linux:**
```bash
# Temporary (current session)
export CONTEXT7_API_KEY="ctx7sk_your_api_key_here"

# Permanent (add to shell profile)
echo 'export CONTEXT7_API_KEY="ctx7sk_your_api_key_here"' >> ~/.bashrc
# or for zsh:
echo 'export CONTEXT7_API_KEY="ctx7sk_your_api_key_here"' >> ~/.zshrc

# Reload shell
source ~/.bashrc  # or source ~/.zshrc
```

#### Method 2: Config File (Recommended for Personal Use)

**User-level config** (applies to all projects):
```bash
# Create config file in home directory
echo "CONTEXT7_API_KEY=ctx7sk_your_api_key_here" > ~/.context7.env

# On Linux/macOS, restrict permissions
chmod 600 ~/.context7.env
```

**Project-level config** (team-specific key):
```bash
# Create config file in project root
echo "CONTEXT7_API_KEY=ctx7sk_your_api_key_here" > .context7.env

# IMPORTANT: Add to .gitignore to keep it private!
echo ".context7.env" >> .gitignore
```

### Check Your API Key Status

```bash
# Check if API key is configured
bash scripts/fetch-docs.sh --api-status

# Or run with verbose to see API key status
bash scripts/fetch-docs.sh --library react --topic hooks --verbose
```

### API Key Priority Order

When multiple sources are configured, the skill uses this priority:

| Priority | Source | Best For |
|----------|--------|----------|
| 1 (Highest) | `CONTEXT7_API_KEY` environment variable | CI/CD, temporary override |
| 2 | `.context7.env` in current directory | Project-specific keys |
| 3 | `~/.context7.env` in home directory | Personal default |
| 4 (Fallback) | No key (low rate limits) | Testing only |

### Troubleshooting API Key Issues

| Issue | Solution |
|-------|----------|
| "Rate limit exceeded" | Get API key at context7.com/dashboard |
| Key not detected | Run `--api-status` to check configuration |
| Wrong key source | Check priority order above |
| Team needs shared key | Use project-level `.context7.env` |

---

## üéØ The Problem

**Context Bloat:** Fetching documentation consumes excessive tokens. A simple query like "Show me React useState examples" returns 934 tokens when you only need ~200 tokens of actual code.

**Token Waste:**
- Direct MCP call ‚Üí 934 tokens per query
- Most content is verbose explanations you don't need
- 78% of response is wasted tokens

**Developer Pain:** Switching to browser, searching docs, finding examples = 5-10 minutes wasted per lookup.

---

## ‚ú® The Solution

Shell pipeline that filters MCP responses **before** they enter Claude's context:

1. Fetch documentation ‚Üí 934 tokens (stays in subprocess ‚úÖ)
2. Filter with grep/awk ‚Üí 0 LLM tokens for processing ‚úÖ
3. Return essentials ‚Üí 205 tokens to Claude ‚úÖ

**Result:** 77% average token savings

Implements the architecture from [Anthropic's "Code Execution with MCP" blog post](https://www.anthropic.com/engineering/code-execution-with-mcp).

---

## üìä Proven Results

### Simple Query Examples

| Query | Direct MCP | This Skill | Tokens Saved | Savings % |
|-------|-----------|------------|--------------|-----------|
| React useState | 934 | 205 | 729 | **78%** |
| Next.js routing | 1,245 | 287 | 958 | **77%** |
| Prisma queries | 1,089 | 256 | 833 | **76%** |
| Express middleware | 876 | 198 | 678 | **77%** |

**Average: 77% token savings**

### Real-World Complex Scenario (QA Evaluation)

**Scenario**: Fixing 8 bugs in FastAPI application requiring multiple documentation lookups

| Metric | Direct MCP | fetch-library-docs | Improvement |
|--------|-----------|--------------|-------------|
| Total tokens | 16,287 | 2,153 | **86.8% savings** |
| Bugs fixed | 8/8 ‚úÖ | 8/8 ‚úÖ | Identical quality |
| Useful content | ~20% | ~85% | **4.25x better** |

### Monthly Impact

**Estimated usage** (20 queries/day):
- Direct MCP: ~560,400 tokens
- This skill: ~123,000 tokens
- **Saved: 437,400 tokens/month**

**Overhead:** ~22 seconds per query for 86.8% savings ‚úÖ

---

## üèóÔ∏è How It Works

### Execution Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User asks Claude: "Show me React useState examples"     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Claude automatically runs:                               ‚îÇ
‚îÇ bash scripts/fetch-docs.sh --library react --topic useState ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ fetch-docs.sh (Orchestrator)                             ‚îÇ
‚îÇ ‚îú‚îÄ Resolves library name to ID                          ‚îÇ
‚îÇ ‚îî‚îÄ Calls fetch-raw.sh                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ fetch-raw.sh (MCP Wrapper)                               ‚îÇ
‚îÇ Calls: python3 mcp-client.py call \                     ‚îÇ
‚îÇ          -s "npx -y @upstash/context7-mcp" \             ‚îÇ
‚îÇ          -t get-library-docs \                            ‚îÇ
‚îÇ          -p '{"context7CompatibleLibraryID": ...}'       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ mcp-client.py (Universal MCP Client)                     ‚îÇ
‚îÇ ‚îú‚îÄ Spawns: npx -y @upstash/context7-mcp                 ‚îÇ
‚îÇ ‚îú‚îÄ Communicates via stdio (JSON-RPC)                    ‚îÇ
‚îÇ ‚îî‚îÄ Returns: 934 tokens (stays in subprocess!)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ fetch-docs.sh receives RAW_JSON (934 tokens)             ‚îÇ
‚îÇ ‚îú‚îÄ Pipes through: extract-code-blocks.sh (awk)          ‚îÇ
‚îÇ ‚îú‚îÄ Pipes through: extract-signatures.sh (awk)           ‚îÇ
‚îÇ ‚îú‚îÄ Pipes through: extract-notes.sh (grep)               ‚îÇ
‚îÇ ‚îî‚îÄ Returns: 205 tokens to Claude                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Token savings: 729 tokens (78%) ‚úÖ
```

### Key Innovation: Subprocess Isolation

The **934-token response never enters Claude's context**:

1. **Subprocess execution**: mcp-client.py runs in separate process
2. **In-memory processing**: MCP response stays in subprocess memory
3. **Zero-token filtering**: awk/grep/sed process text (0 LLM tokens!)
4. **Selective return**: Only 205 filtered tokens go to Claude

**Components:**
- **mcp-client.py**: Universal MCP client (foundation)
- **fetch-raw.sh**: Wrapper for MCP calls
- **extract-*.sh**: Filtering scripts (awk/grep/sed)
- **fetch-docs.sh**: Orchestrator

---

## üî¨ Comprehensive QA Evaluation

**Independent evaluation by Senior QA Engineer (15+ years experience)**

### Test Scenario
Complex FastAPI application with 8 subtle bugs requiring library documentation:
- Async context managers
- Deprecated lifecycle events
- Background task dependencies
- Error handling patterns

### Results Summary

| Metric | fetch-library-docs | Direct MCP | Advantage |
|--------|--------------|------------|-----------|
| **Token Efficiency** | 2,153 tokens | 16,287 tokens | **86.8% savings** |
| **Time** | 88 seconds | 52 seconds | 40% slower |
| **Bugs Fixed** | 8/8 ‚úÖ | 8/8 ‚úÖ | **Identical quality** |
| **Signal-to-Noise** | ~85% useful | ~20% useful | **4.25x better** |
| **Context Preserved** | 14,134 tokens | 0 tokens | **7.6x better** |
| **Queries Possible** | ~37 queries | ~6 queries | **6x more** |

### Key Findings

‚úÖ **Identical solution quality** at 86.8% lower token cost
‚úÖ **Better signal-to-noise ratio** (85% vs 20% useful content)
‚úÖ **6x more documentation queries** possible within context budget
‚úÖ **High-precision filtering** keeps only code examples + signatures + notes

**Recommendation**: fetch-library-docs is the superior choice for typical Claude Code workflows. Token efficiency gains (7.6x improvement) far outweigh the time cost (40% slower).

üìä **[Read Full QA Evaluation Report](../../../skill-evaluation/QA_EVALUATION_REPORT.md)** - Comprehensive comparison with detailed metrics, test code, and recommendations

---

## üöÄ Quick Start

### Prerequisites

1. **Get your API key** (free): [context7.com/dashboard](https://context7.com/dashboard)
2. **Setup your API key** (one-time):
   ```bash
   # Save to config file
   echo "CONTEXT7_API_KEY=ctx7sk_your_key_here" > ~/.context7.env
   ```

### Usage

#### Automatic (Recommended)

Just ask Claude about any library:

```
"Show me React useState examples"
"How do I use Next.js routing?"
"What's the Prisma query syntax?"
```

Claude automatically uses this skill with 77% token savings!

#### Manual Testing

```bash
cd ~/.claude/skills/fetch-library-docs

# Check API key status
bash scripts/fetch-docs.sh --api-status

# Basic usage
bash scripts/fetch-docs.sh --library react --topic useState

# With statistics (shows API key status too)
bash scripts/fetch-docs.sh --library react --topic useState --verbose
# Shows: API Key: configured (user config)
#        Raw response: ~934 tokens
#        Filtered output: ~205 tokens
#        Token savings: 78%
```

### Common Library IDs

```bash
React:     /reactjs/react.dev
Next.js:   /vercel/next.js
Express:   /expressjs/express
Prisma:    /prisma/docs
MongoDB:   /mongodb/docs
```

---

## üìö Documentation

- **[SKILL.md](SKILL.md)** - Technical reference
- **[TOKEN-SAVINGS-ARCHITECTURE.md](TOKEN-SAVINGS-ARCHITECTURE.md)** - Architecture details
- **[SHELL-PIPELINE-SOLUTION.md](../../SHELL-PIPELINE-SOLUTION.md)** - Complete solution guide
- **[QA Evaluation Report](../../../skill-evaluation/QA_EVALUATION_REPORT.md)** - Comprehensive QA evaluation and comparison

---

## üîó References

### Anthropic's MCP Blog

**["Code Execution with MCP"](https://www.anthropic.com/engineering/code-execution-with-mcp)**

Key patterns implemented:
- ‚úÖ Subprocess isolation for MCP responses
- ‚úÖ Zero-token processing with native tools
- ‚úÖ Selective data return to LLM context

### MCP Protocol

- **[Model Context Protocol](https://modelcontextprotocol.io/)** - Official spec
- **[Context7 MCP Server](https://www.npmjs.com/package/@upstash/context7-mcp)** - Documentation provider

---

## üö® Troubleshooting

### API Key Issues

| Issue | Solution |
|-------|----------|
| "Rate limit exceeded" | Get free API key at [context7.com/dashboard](https://context7.com/dashboard) |
| "Too many requests" (429) | API key not configured or rate limit hit |
| Key not working | Check status with `bash scripts/fetch-docs.sh --api-status` |
| Need project-specific key | Use `.context7.env` in project root |

### General Issues

| Issue | Solution |
|-------|----------|
| "npx: command not found" | Install Node.js: `sudo apt-get install nodejs npm` |
| Library not found | Try variations: "next.js" ‚Üí "nextjs" |
| No results | Try broader topic or `--mode info` |
| Need more results | Use `--page 2` for pagination |

---

## üèÜ Bottom Line

**Problem:** Documentation lookups waste tokens and time

**Solution:** Shell pipeline filters MCP responses before reaching Claude

**Results:**
- ‚úÖ 77% average token savings
- ‚úÖ 100% functionality preserved
- ‚úÖ 300ms processing overhead
- ‚úÖ 437,400 tokens saved monthly

**Use when:**
- You need library documentation
- You want code examples
- You're learning a new API
- You care about token efficiency

**Impact:**
- Time: 5 minutes ‚Üí 10 seconds per lookup
- Tokens: 934 ‚Üí 205 per query (78% savings)
- Cost: Significantly reduced monthly spend

---

*Built with the architecture from [Anthropic's "Code Execution with MCP" blog post](https://www.anthropic.com/engineering/code-execution-with-mcp)*
